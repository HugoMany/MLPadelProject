{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTF Model for predicting racket age using P1, P2 and P3, based on peaks features - Sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "This notebook implements a Random Tree Forest (RTF) model to predict the age of a racket (P1, P2, P3) based on sound features extracted from audio files. The workflow involves reading `.wav` files, extracting frequency peaks using FFT, and training the model using these features. The model's performance is evaluated using accuracy metrics and visualized through scatter plots and confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tools Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reach the project root\n",
    "notebook_path = os.path.abspath('')\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '../../../'))\n",
    "functions_path = os.path.join(project_root, 'Functions')\n",
    "\n",
    "# Add Functions folder\n",
    "if functions_path not in sys.path:\n",
    "    sys.path.append(functions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "\n",
    "from readWavFolder import readWavFolder\n",
    "from spectrumFromWav import spectrumFromWav\n",
    "from extractNPeak import extractPeakFromSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNPeak(n_peak,signal):\n",
    "    # Find peaks in the signal\n",
    "    peaks = np.argsort(signal)[-n_peak:]  # Get indices of the n largest peaks\n",
    "    peaks = np.sort(peaks)  # Sort the indices in ascending order\n",
    "\n",
    "    # Extract the peak values\n",
    "    peak_values = signal[peaks]\n",
    "\n",
    "    return peaks, peak_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len(allWavFileP1) 213 Len(allWavFileP2) 213 Len(allWavFileP3) 213\n"
     ]
    }
   ],
   "source": [
    "# Liste des types de raquettes et zones\n",
    "raquetteTypeList = {\"RB\":0, \"RO\":1, \"RR\":2, \"RV\":3}\n",
    "racket_ages = {\"P1\":1, \"P2\":2, \"P3\":3}\n",
    "\n",
    "allWavFile=[]\n",
    "allWavFileLabel=[]\n",
    "allWavFileP1=[]\n",
    "allWavFileP2=[]\n",
    "allWavFileP3=[]\n",
    "\n",
    "#P1\n",
    "sampleRateFolderP1,allWavFileP1,filesP1 = readWavFolder(\"../../../Data/Sound/P1\")\n",
    "\n",
    "#P2\n",
    "sampleRateFolderP2,allWavFileP2,filesP2 = readWavFolder(\"../../../Data/Sound/P2\")\n",
    "\n",
    "#P3\n",
    "sampleRateFolderP3,allWavFileP3,filesP3 = readWavFolder(\"../../../Data/Sound/P3\")\n",
    "\n",
    "\n",
    "# Find the minimum length among the three lists\n",
    "min_len = min(len(allWavFileP1), len(allWavFileP2), len(allWavFileP3))\n",
    "\n",
    "# Reduce each list to the minimum length\n",
    "allWavFileP1 = allWavFileP1[:min_len]\n",
    "allWavFileP2 = allWavFileP2[:min_len]\n",
    "allWavFileP3 = allWavFileP3[:min_len]\n",
    "\n",
    "print(\"Len(allWavFileP1)\",len(allWavFileP1),\"Len(allWavFileP2)\",len(allWavFileP2),\"Len(allWavFileP3)\",len(allWavFileP3))\n",
    "\n",
    "\n",
    "# print(len(sampleRateFolderP1))\n",
    "\n",
    "for wavFile in allWavFileP1:\n",
    "    allWavFile.append(wavFile)\n",
    "    allWavFileLabel.append(\"P1\")\n",
    "for wavFile in allWavFileP2:\n",
    "    allWavFile.append(wavFile)\n",
    "    allWavFileLabel.append(\"P2\")\n",
    "for wavFile in allWavFileP3:\n",
    "    allWavFile.append(wavFile)\n",
    "    allWavFileLabel.append(\"P3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPeakHZAllWavFile = []\n",
    "bestPeakAmplitudeAllWavFile = []\n",
    "n_peak = 10\n",
    "\n",
    "for wavFile in allWavFile:\n",
    "    # Compute the spectrum using FFT\n",
    "    spectrum = spectrumFromWav(wavFile)\n",
    "\n",
    "    # Extract peaks from the spectrum\n",
    "    peaks_HZ, peak_Amplitude = extractPeakFromSignal(spectrum, n_peak)\n",
    "    \n",
    "    bestPeakHZAllWavFile.append(peaks_HZ)\n",
    "    bestPeakAmplitudeAllWavFile.append(peak_Amplitude[\"peak_heights\"])\n",
    "\n",
    "    # Normaliser les amplitudes\n",
    "    bestPeakAmplitudeAllWavFile = [amp / np.max(amp) for amp in bestPeakAmplitudeAllWavFile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (639,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Combine features into X\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39marray(bestPeakHZAllWavFile), np\u001b[38;5;241m.\u001b[39marray(bestPeakAmplitudeAllWavFile)])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Encode string labels into integers\u001b[39;00m\n\u001b[0;32m      5\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (639,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Combine features into X\n",
    "X = np.hstack([np.array(bestPeakHZAllWavFile), np.array(bestPeakAmplitudeAllWavFile)])\n",
    "\n",
    "# Encode string labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(allWavFileLabel)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les bonnes valeurs trouvé\n",
    "n_estimators_range = [10, 50, 100]\n",
    "max_depth_range = [None, 10, 20, 30]\n",
    "min_samples_split_range = [2, 5, 10]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Tester toutes les combinaisons d'hyperparamètres\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        for min_samples_split in min_samples_split_range:\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                max_depth=max_depth,\n",
    "                min_samples_split=min_samples_split,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "            y_train_pred = rf.predict(X_train)\n",
    "\n",
    "            results.append({\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'accuracy_train': accuracy_score(y_train, y_train_pred),\n",
    "                'accuracy_test': accuracy_score(y_test, y_pred)\n",
    "            })\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Trier les résultats par ordre décroissant de 'accuracy_test'\n",
    "sorted_results_df = results_df.sort_values(by='accuracy_test', ascending=False)\n",
    "\n",
    "print(sorted_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color map for the labels\n",
    "colors = ['red', 'blue', 'green']\n",
    "ageList = {\"P1\": 1, \"P2\": 2, \"P3\": 3}\n",
    "label_names = list(ageList.keys())\n",
    "\n",
    "# Create a scatter plot for the training data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1) # First subplot for training data\n",
    "for label_idx, label_name in enumerate(label_names):\n",
    "    # Filter data points for the current label\n",
    "    label_data = X_train[y_train == label_idx]\n",
    "    for sample in label_data:\n",
    "        # Add 150Hz because of the filter and filter frequencies <= 1250 Hz\n",
    "        frequencies = sample[:n_peak] + 150\n",
    "        amplitudes = sample[n_peak:]\n",
    "        mask = frequencies <= 550\n",
    "        plt.scatter(frequencies[mask], amplitudes[mask], color=colors[label_idx], alpha=0.3)\n",
    "\n",
    "plt.title(\"Training Data: Frequencies vs Amplitudes (Age P1, P2, P3)\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Normalized Amplitude\")\n",
    "plt.grid()\n",
    "\n",
    "# Create a scatter plot for the test data with predictions\n",
    "plt.subplot(1, 2, 2) # Second subplot for test data with predictions\n",
    "y_pred = rf.predict(X_test) # Get predictions for test data\n",
    "\n",
    "for i, sample in enumerate(X_test):\n",
    "    true_label = y_test[i]\n",
    "    pred_label = y_pred[i]\n",
    "\n",
    "    # Add 150Hz because of the filter and filter frequencies <= 1250 Hz\n",
    "    frequencies = sample[:n_peak] + 150\n",
    "    amplitudes = sample[n_peak:]\n",
    "    mask = frequencies <= 550\n",
    "\n",
    "    # Plot with solid color if prediction is correct, otherwise use a different marker\n",
    "    if true_label == pred_label:\n",
    "        plt.scatter(frequencies[mask], amplitudes[mask], color=colors[pred_label], alpha=0.3)\n",
    "    else:\n",
    "        # Use 'x' marker for incorrect predictions\n",
    "        plt.scatter(frequencies[mask], amplitudes[mask], color=colors[pred_label], marker='x', s=100, alpha=0.3)\n",
    "\n",
    "# Add a legend\n",
    "for label_idx, label_name in enumerate(label_names):\n",
    "    plt.scatter([], [], color=colors[label_idx], label=f\"Age {label_name}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"Test Predictions: Frequencies vs Amplitudes (Accuracy: {accuracy_score(y_test, y_pred):.2f})\")\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Normalized Amplitude\")\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=label_encoder.classes_)\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
