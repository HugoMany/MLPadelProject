{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTF Model for predicting racket type using P1, P2 and P3, based on energy per band features - Sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "This notebook implements a Random Tree Forest (RTF) model to predict the type of a racket (RB, RO, RR, RV) based on sound features extracted from audio files. The workflow involves reading `.wav` files, extracting frequency peaks using FFT, and training the model using these features. The model's performance is evaluated using accuracy metrics and visualized through scatter plots and confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tools Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reach the project root\n",
    "notebook_path = os.path.abspath('')\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '../../../'))\n",
    "functions_path = os.path.join(project_root, 'Functions')\n",
    "\n",
    "# Add Functions folder\n",
    "if functions_path not in sys.path:\n",
    "    sys.path.append(functions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "\n",
    "from readWavFolder import readWavFolder\n",
    "from spectrumFromSignal import spectrumFromSignal\n",
    "from energy_per_frequency_band_from_spectrum import energy_per_frequency_band_from_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des types de raquettes\n",
    "raquetteTypeList = {\"RB\": 0, \"RO\": 1, \"RR\": 2, \"RV\": 3}\n",
    "\n",
    "# Liste pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "for bd in range(10,101,5):\n",
    "\n",
    "    X_Hz = []\n",
    "    X_Amplitude = []\n",
    "    Y_Label = []\n",
    "    used = False\n",
    "    #print(bd)\n",
    "\n",
    "    # Create a DataFrame to store details of each wav file\n",
    "    wav_files_data = []\n",
    "\n",
    "    # Process each folder (P1, P2, P3)\n",
    "    for folder, folder_path in [(\"P1\", \"../../../Data/Sound/P1\"), \n",
    "                                (\"P2\", \"../../../Data/Sound/P2\"), \n",
    "                                (\"P3\", \"../../../Data/Sound/P3\")]:\n",
    "        sample_rates, wav_files, file_names = readWavFolder(folder_path)\n",
    "        \n",
    "        for sample_rate, wav_file, file_name in zip(sample_rates, wav_files, file_names):\n",
    "            wav_files_data.append({\n",
    "                \"Folder\": folder,\n",
    "                \"File_Name\": file_name,\n",
    "                \"Sample_Rate\": sample_rate,\n",
    "                \"Signal\": wav_file\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    wav_files_df = pd.DataFrame(wav_files_data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    #print(wav_files_df)\n",
    "\n",
    "    spectrumVect = []\n",
    "\n",
    "    # For each wav file, extract its spectrum, filter it between 150 and 1000 Hz, and take the top n peaks\n",
    "    for i in range(len(wav_files_df[\"Signal\"])):\n",
    "        if \"C\" in wav_files_df[\"File_Name\"][i]:\n",
    "            if 'RB' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RB'\n",
    "            elif 'RR' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RR'\n",
    "            elif 'RO' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RO'\n",
    "            elif 'RV' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RV'\n",
    "\n",
    "            # Extract the spectrum from the wav file\n",
    "            spectrum, freqs = spectrumFromSignal(wav_files_df[\"Signal\"][i], wav_files_df[\"Sample_Rate\"][i])\n",
    "            spectrumVect.append(freqs)\n",
    "\n",
    "            band_energies, band_frequencies = energy_per_frequency_band_from_spectrum(spectrum, freqs[(freqs >= 150) & (freqs <= 1000)], bd)\n",
    "\n",
    "            X_Hz.append(band_frequencies)\n",
    "            X_Amplitude.append(band_energies)\n",
    "\n",
    "            Y_Label.append(raquetteType)\n",
    "    \n",
    "    # On normalise les amplitudes\n",
    "    X_Amplitude = [peak_values / np.max(peak_values) for peak_values in X_Amplitude]\n",
    "\n",
    "    # Ensure all arrays in X_peaksHz and X_peaksAmplitude have the same length\n",
    "    max_length = max(max(len(peaks) for peaks in X_Hz), max(len(amps) for amps in X_Amplitude))\n",
    "    X_Hz_padded = [np.pad(peaks, (0, max_length - len(peaks)), constant_values=0) for peaks in X_Hz]\n",
    "    X_Amplitude_padded = [np.pad(amps, (0, max_length - len(amps)), constant_values=0) for amps in X_Amplitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the frequencies and amplitudes into a single feature matrix\n",
    "X = np.hstack((np.array(X_Hz_padded), np.array(X_Amplitude_padded)))\n",
    "\n",
    "# Encode string labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(Y_Label)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     band_width  n_estimators  max_depth  min_samples_split  accuracy_train  \\\n",
      "149         100           100       40.0                 10        0.987448   \n",
      "146         100           100       30.0                 10        0.987448   \n",
      "143         100           100       20.0                 10        0.987448   \n",
      "140         100           100       10.0                 10        0.987448   \n",
      "137         100           100        NaN                 10        0.987448   \n",
      "..          ...           ...        ...                ...             ...   \n",
      "3           100            10       10.0                  2        0.993724   \n",
      "12          100            10       40.0                  2        0.995816   \n",
      "6           100            10       20.0                  2        0.995816   \n",
      "9           100            10       30.0                  2        0.995816   \n",
      "0           100            10        NaN                  2        0.995816   \n",
      "\n",
      "     accuracy_test  \n",
      "149       0.950000  \n",
      "146       0.950000  \n",
      "143       0.950000  \n",
      "140       0.950000  \n",
      "137       0.950000  \n",
      "..             ...  \n",
      "3         0.908333  \n",
      "12        0.883333  \n",
      "6         0.883333  \n",
      "9         0.883333  \n",
      "0         0.883333  \n",
      "\n",
      "[150 rows x 6 columns]\n",
      "Results have been saved to 'S_RTF_Racket_P1.P2.P3_Energy.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Random Forest algorithm parameters\n",
    "n_estimators_range = range(10, 101, 10)  # Number of trees between 10 and 100\n",
    "max_depth_range = [None, 10, 20, 30, 40]  # Different depths\n",
    "min_samples_split_range = [2, 5, 10]  # Minimum number to divide a node\n",
    "min_samples_leaf_range = [1, 2, 4]  # Minimum number of samples in a sheet\n",
    "max_features_range = ['sqrt', 'log2', None]  # Number of features per tree\n",
    "\n",
    "# Test all the combinations of parameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        for min_samples_split in min_samples_split_range:\n",
    "            # Create and train the Random Forest model\n",
    "            rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_samples_split=min_samples_split, random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate on the test set\n",
    "            y_pred = rf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Evaluate on the training set\n",
    "            y_train_pred = rf.predict(X_train)\n",
    "            accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "            # Add the results to the list\n",
    "            results.append({\n",
    "                'band_width': bd,\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'accuracy_train': accuracy_train,\n",
    "                'accuracy_test': accuracy_test\n",
    "            })\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the results by accuracy_test in descending order\n",
    "sorted_results_df = results_df.sort_values(by='accuracy_test', ascending=False)\n",
    "\n",
    "print(sorted_results_df)\n",
    "\n",
    "# Register the best parameters in a CSV file\n",
    "sorted_results_df.to_csv(\"S_RTF_Racket_P1.P2.P3_Energy.csv\", index=False)\n",
    "\n",
    "print(\"Results have been saved to 'S_RTF_Racket_P1.P2.P3_Energy.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
