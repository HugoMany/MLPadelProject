{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTF Model for predicting zone with Peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readwav function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readWavFolder(folderPath):\n",
    "    fileFolder=[]\n",
    "    sampleRateFolder=[]\n",
    "\n",
    "    files = os.listdir(folderPath)\n",
    "    for filename in glob.glob(os.path.join(folderPath, '*.wav')):\n",
    "        samplerate, data = wavfile.read(filename)\n",
    "        fileFolder.append(data)\n",
    "        sampleRateFolder.append(samplerate)\n",
    "    return sampleRateFolder, fileFolder, files\n",
    "    \n",
    "samplerateVect,testWavFileVect,filename = readWavFolder(\"../../Data_Clean/new_RB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrumFromWav(wavFile,sampleRate,chanel):\n",
    "    spectrum = fft(wavFile[:, chanel])  # Compute the FFT for the first channel\n",
    "    return abs(spectrum[:len(spectrum) // 2])  # Return the magnitude of the spectrum (half due to symmetry)\n",
    "\n",
    "\n",
    "spectrumVect=[]\n",
    "for i in range(len(testWavFileVect)):\n",
    "    spectrum = spectrumFromWav(testWavFileVect[i], samplerateVect[i],0)\n",
    "    freqs = np.fft.fftfreq(len(spectrum) * 2, d=1/samplerateVect[i])[:len(spectrum)]\n",
    "    filtered_spectrum = spectrum[(freqs >= 150) & (freqs <= 1000)]\n",
    "    spectrumVect.append(filtered_spectrum)\n",
    "\n",
    "\n",
    "#for idx, spectrum in enumerate(spectrumVect[:3]):\n",
    "    #plt.figure(figsize=(6, 3))\n",
    "    #plt.plot(spectrum)\n",
    "    #plt.title(f\"Spectrum {idx + 1}\")\n",
    "    #plt.xlabel(\"Frequency Bin\")\n",
    "    #plt.ylabel(\"Magnitude\")\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract each peak and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNPeak(n_peak,signal):\n",
    "    # Find peaks in the signal\n",
    "    peaks = np.argsort(signal)[-n_peak:]  # Get indices of the n largest peaks\n",
    "    peaks = np.sort(peaks)  # Sort the indices in ascending order\n",
    "\n",
    "    # Extract the peak values\n",
    "    peak_values = signal[peaks]\n",
    "\n",
    "    return peaks, peak_values\n",
    "\n",
    "extractNPeak(20,spectrumVect[0])\n",
    "\n",
    "# Fonction pour lire les fichiers d'un dossier donné\n",
    "def lire_fichiers_dossier(dossier):\n",
    "    if os.path.exists(dossier):  # Vérifier si le dossier existe\n",
    "        return readWavFolder(dossier)\n",
    "    else:\n",
    "        print(f\"Dossier introuvable : {dossier}\")\n",
    "        return [], [], []  # Retourne des listes vides si le dossier n'existe pas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chanel 0\n",
      "Nbr_peak 5\n",
      "Nbr_peak 10\n",
      "Nbr_peak 15\n",
      "Nbr_peak 20\n",
      "Nbr_peak 25\n",
      "Nbr_peak 30\n",
      "Nbr_peak 35\n",
      "Nbr_peak 40\n",
      "Nbr_peak 45\n",
      "Nbr_peak 50\n",
      "Nbr_peak 55\n",
      "Nbr_peak 60\n",
      "Nbr_peak 65\n",
      "Nbr_peak 70\n",
      "Nbr_peak 75\n",
      "Nbr_peak 80\n",
      "Nbr_peak 85\n",
      "Nbr_peak 90\n",
      "Nbr_peak 95\n",
      "Nbr_peak 100\n",
      "Chanel 1\n",
      "Nbr_peak 5\n",
      "Nbr_peak 10\n",
      "Nbr_peak 15\n",
      "Nbr_peak 20\n",
      "Nbr_peak 25\n",
      "Nbr_peak 30\n",
      "Nbr_peak 35\n",
      "Nbr_peak 40\n",
      "Nbr_peak 45\n",
      "Nbr_peak 50\n",
      "Nbr_peak 55\n",
      "Nbr_peak 60\n",
      "Nbr_peak 65\n",
      "Nbr_peak 70\n",
      "Nbr_peak 75\n",
      "Nbr_peak 80\n",
      "Nbr_peak 85\n",
      "Nbr_peak 90\n",
      "Nbr_peak 95\n",
      "Nbr_peak 100\n",
      "Results have been saved to 'RTF_ZONE_P1_Peaks.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Liste des types de raquettes et zones\n",
    "racket_names = {\"RB\":1, \"RO\":2, \"RR\":3, \"RV\":4}\n",
    "zone_names = {\"C\":1, \"S\":2, \"V\":3}\n",
    "\n",
    "# Liste pour stocker les résultats\n",
    "results = []\n",
    "for chanel in range(1, 3):\n",
    "    if chanel == 1:\n",
    "        c = 0\n",
    "    else:\n",
    "        c = 1\n",
    "    print(\"Chanel\", c)\n",
    "\n",
    "    for i in range(1, 21):\n",
    "        n_peak = i * 5\n",
    "        X_peaksHz = []\n",
    "        X_peaksAmplitude = []\n",
    "        Y_Label = []\n",
    "        print(\"Nbr_peak\", n_peak)\n",
    "\n",
    "        # Lire les fichiers des raquettes\n",
    "        for raquetteType in racket_names:\n",
    "            dossier_raquette = f\"../../Data_Clean/new_{raquetteType}\"\n",
    "            samplerateVect, WavFileVect, filesName = lire_fichiers_dossier(dossier_raquette)\n",
    "\n",
    "            spectrumVect = []\n",
    "\n",
    "            # Pour chaque fichier wav on extrait son spectre et on le filtre entre 150 et 1000hz et on prend les n meilleurs peaks\n",
    "            for i in range(len(WavFileVect)):\n",
    "\n",
    "                # On extrait la zone\n",
    "                if \"C\" in filesName[i]:\n",
    "                    zone = 'C'\n",
    "                if 'S' in filesName[i]:\n",
    "                    zone = 'S'\n",
    "                if 'V' in filesName[i]:\n",
    "                    zone = 'V'\n",
    "\n",
    "                spectrum = spectrumFromWav(WavFileVect[i], samplerateVect[i], c)\n",
    "                freqs = np.fft.fftfreq(len(spectrum) * 2, d=1 / samplerateVect[i])[:len(spectrum)]\n",
    "                filtered_spectrum = spectrum[(freqs >= 150) & (freqs <= 1000)]\n",
    "                spectrumVect.append(filtered_spectrum)  # Ajout dans spectrumVect\n",
    "\n",
    "                # Utilisation du dernier élément ajouté\n",
    "                peaks, peak_values = extractNPeak(n_peak, spectrumVect[-1])\n",
    "\n",
    "                X_peaksHz.append(peaks)\n",
    "                X_peaksAmplitude.append(peak_values)\n",
    "\n",
    "                Y_Label.append(zone)\n",
    "\n",
    "        # On normalise les amplitudes\n",
    "        X_peaksAmplitude = [peak_values / np.max(peak_values) for peak_values in X_peaksAmplitude]\n",
    "\n",
    "        # Ensure all arrays in X_peaksHz and X_peaksAmplitude have the same length\n",
    "        max_length = max(max(len(peaks) for peaks in X_peaksHz), max(len(amps) for amps in X_peaksAmplitude))\n",
    "        X_peaksHz_padded = [np.pad(peaks, (0, max_length - len(peaks)), constant_values=0) for peaks in X_peaksHz]\n",
    "        X_peaksAmplitude_padded = [np.pad(amps, (0, max_length - len(amps)), constant_values=0) for amps in X_peaksAmplitude]\n",
    "\n",
    "        # Combine the frequencies and amplitudes into a single feature matrix\n",
    "        X = np.hstack((np.array(X_peaksHz_padded), np.array(X_peaksAmplitude_padded)))\n",
    "\n",
    "        # Encode string labels into integers\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(Y_Label)\n",
    "\n",
    "        # Diviser les données en ensembles d'entraînement et de test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=True)\n",
    "\n",
    "        # Paramètres de l'algorithme Random Forest\n",
    "        n_estimators_range = range(10, 101, 10)  # Nombre d'arbres entre 10 et 100\n",
    "        max_depth_range = [None, 10, 20, 30, 40]  # Profondeurs différentes\n",
    "        min_samples_split_range = [2, 5, 10]  # Nombre minimum pour diviser un nœud\n",
    "        min_samples_leaf_range = [1, 2, 4]  # Nombre minimum d'échantillons dans une feuille\n",
    "        max_features_range = ['sqrt', 'log2', None]  # Nombre de features par arbre\n",
    "\n",
    "        # Tester toutes les combinaisons d'hyperparamètres\n",
    "        for n_estimators in n_estimators_range:\n",
    "            for max_depth in max_depth_range:\n",
    "                for min_samples_split in min_samples_split_range:\n",
    "                    # Créer et entraîner le modèle Random Forest\n",
    "                    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                                min_samples_split=min_samples_split, random_state=42)\n",
    "                    rf.fit(X_train, y_train)\n",
    "\n",
    "                    # Évaluer sur l'ensemble de test\n",
    "                    y_pred = rf.predict(X_test)\n",
    "                    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                    # Évaluer sur l'ensemble d'entraînement\n",
    "                    y_train_pred = rf.predict(X_train)\n",
    "                    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "                    # Switch case pour le canal\n",
    "                    if c == 0:\n",
    "                        channel_name = \"Left\"\n",
    "                    elif c == 1:\n",
    "                        channel_name = \"Right\"\n",
    "\n",
    "                    # Ajouter le nom du canal aux résultats\n",
    "                    results.append({\n",
    "                        'Chanel_Name': channel_name,\n",
    "                        'nbr_de_peak': n_peak,\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'max_depth': max_depth,\n",
    "                        'min_samples_split': min_samples_split,\n",
    "                        'accuracy_train': accuracy_train,\n",
    "                        'accuracy_test': accuracy_test\n",
    "                    })\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Enregistrer les résultats dans un fichier Excel\n",
    "results_df.to_excel(\"RTF_ZONE_P1_Peaks.xlsx\", index=False)\n",
    "\n",
    "print(\"Results have been saved to 'RTF_ZONE_P1_Peaks.xlsx'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
